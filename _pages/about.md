---
layout: about
title: about
permalink: /
description: 

profile:
  align: left
  image: prof_pic.jpg

news: true  # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false  # includes social icons at the bottom of the page

---

I am a Ph.D. Candidate advised by <a href="https://faisal.ai">Faisal Mahmood</a> at <a href="https://bigphd.hms.harvard.edu/">Harvard University</a>, and also within Brigham and Women's Hospital, Dana-Farber Cancer Institute, and the Broad Institute.

Prior to starting my Ph.D., I obtained my B.S/M.S. in Biomedical Engineering and Computer Science at Johns Hopkins University, where I worked with <a href="https://durr.jhu.edu">Nicholas Durr</a> and <a href="https://ccvl.jhu.edu/">Alan Yuille</a>. I am fortunate to have also spent time working at worked at Apple Inc. in the Health Special Project and Applied Machine Learning Groups (with <a href="https://scholar.google.com/citations?user=3CS_ahUAAAAJ&hl=en">Belle Tseng</a> and <a href="https://www.gatesfoundation.org/about/leadership/andrew-trister">Andrew Trister</a>), Microsoft Research in the BioML Group (with <a href="http://www.cs.toronto.edu/~rahulgk/index.html">Rahul Gopalkrishnan</a>), and at the National Institutes of Health in NIBIB (with <a href="https://www.nibib.nih.gov/labs-at-nibib/laboratory-cellular-imaging-and-macromolecular-biophysics-lcimb">Richard Leapman</a>).

### Research Highlights

- **Multimodal Integration**: Multimodal learning has emerged as an interdisciplinary field to solve many core problems in machine perception, human-computer interaction, and recently in biology & medicine, in which there is often an enormous wealth of multimodal data collected in parallel to study the same underlying disease. Since first starting out in research, I have a range of experiences working on multimodal learning for integrating: 1) <a href="https://machinelearning.apple.com/research/developing-measures-of-cognitive-impairment-in-the-real-world-from-consumer-grade-multimodal-sensor-streams">multimodal sensor streams from the Apple Watch and iPhone Data</a> to predict mild cognitive decline, 2) <a href="https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy">RGB and depth images</a> for non-polyploidal lesion classification and SLAM in surgical robotics,  and 3) <a href="https://arxiv.org/abs/2108.02278">pathology images and genomics</a> for cancer prognosis.

- **Weakly-Supervised & Set-Based Deep Learning**: Though deep learning has revolutionized computer vision in many disciplines, gigapixel whole-slide imaging (WSI) in computational pathology is a complex computer vision domain that renders traditional, Convnet-based supervised learning approaches infeasible. To address this issue, I have been working on <a href="https://www.nature.com/articles/s41551-020-00682-w">interpretting large gigapixel images as permutation-invariant sets</a> (or bags in MIL literature), and then developing set-based learning algorithms for weakly-supervised learning on WSIs.


- **Synthetic Data Generation & Domain Adaption**: "What constitutes authenticity, and how would the lack of authenticity shape our perception of reality?" The science fiction American writer Philip K. Dick posited similar questions throughout his literary career and, in particular, in his 1972 essay "How to build a universe that doesnâ€™t fall apart two days later". I am interested in: <a href="https://arxiv.org/abs/1711.06606">using synthetic data for domain adaptation / generalization</a>, <a href="https://github.com/CapsuleEndoscope/VirtualCapsuleEndoscopy"> developing synthetic environments for simulating challenging scenarios for neural networks</a>, as well as the the <a href="https://www.nature.com/articles/s41551-021-00751-8">policy challenges in training AI-SaMDs with synthetic data</a>,


Please feel free to contact me through <a href="mailto:richardchen@.g.harvard.edu">email</a> if you have any questions and interest in collaborating!

{% comment %} 
Write your biography here. Tell the world about yourself. Link to your favorite [subreddit](http://reddit.com){:target="\_blank"}. You can put a picture in, too. The code is already in, just name your picture `prof_pic.jpg` and put it in the `img/` folder.

Put your address / P.O. box / other info right below your picture. You can also disable any these elements by editing `profile` property of the YAML header of your `_pages/about.md`. Edit `_bibliography/papers.bib` and Jekyll will render your [publications page](/al-folio/publications/) automatically.

Link to your social media connections, too. This theme is set up to use [Font Awesome icons](http://fortawesome.github.io/Font-Awesome/){:target="\_blank"} and [Academicons](https://jpswalsh.github.io/academicons/){:target="\_blank"}, like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.

on synthetic data generation, depth estimation, multimodal image fusion, and scene understanding in the gastrointestinal tract. 

, where I developed multimodal approaches for jointly representating, visualizing, and integrating sensor and app-usage data streams from Apple devices (along with other health initatives).
{% endcomment %}
